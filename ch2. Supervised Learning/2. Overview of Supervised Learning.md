# 2. Overview of Supervised Learning

## Reference

* RSS 미분

    <a href="https://math.stackexchange.com/questions/2387495/how-do-you-differentiate-a-matrix-equation-with-respect-to-a-vector">https://math.stackexchange.com/questions/2387495/how-do-you-differentiate-a-matrix-equation-with-respect-to-a-vector</a>

* function approximation

    <a href="https://machinelearningmastery.com/neural-networks-are-function-approximators/">https://machinelearningmastery.com/neural-networks-are-function-approximators/</a>


* Senarios

    <a href="https://stats.stackexchange.com/questions/81197/can-someone-please-explain-to-me-what-the-particular-scenarios-mean
">https://stats.stackexchange.com/questions/81197/can-someone-please-explain-to-me-what-the-particular-scenarios-mean
</a>

* eq_2.9-2.13

    <a href="https://kitech.tistory.com/6?category=793139">https://kitech.tistory.com/6?category=793139</a>

* 조건부평균

    <a href="https://datascienceschool.net/02%20mathematics/07.06%20%EC%A1%B0%EA%B1%B4%EB%B6%80%EA%B8%B0%EB%8C%93%EA%B0%92%EA%B3%BC%20%EC%98%88%EC%B8%A1%20%EB%AC%B8%EC%A0%9C.html">https://datascienceschool.net/02%20mathematics/07.06%20%EC%A1%B0%EA%B1%B4%EB%B6%80%EA%B8%B0%EB%8C%93%EA%B0%92%EA%B3%BC%20%EC%98%88%EC%B8%A1%20%EB%AC%B8%EC%A0%9C.html</a>

* Decision Theory

    <a href="http://sanghyukchun.github.io/61/">http://sanghyukchun.github.io/61/</a>

* eq_2.27~2.30

    <a href="https://wtfaretheysaying.wordpress.com/tag/esl/">https://wtfaretheysaying.wordpress.com/tag/esl/</a>

* MLE(Maximum Likelihood Estimate)

    <a href="https://hyeongminlee.github.io/post/bnn002_mle_map/">https://hyeongminlee.github.io/post/bnn002_mle_map/</a>

## 2.1. Introduction

input값을 통해 output값을 예측하는 일련의 과정인 'supervised learning'(지도학습)에 대해 알아보자.

## 2.2. Variable Types and Terminology

### type of variables

* Qualitative variable

    각 결과값들 간의 순서가 존재하지 않으며, 숫자나 값이 class 형태로 사용되는 경우. 이를 'categorical' or 'discrete'하다고 한다.

    * Usage for Input / output

        Input으로는 다차원의 categorical한 정보를 담기도 하는데, 이를 위해서 K-level한 변수를 각 컬럼으로 나누는 dummy variable을 생성하여 나타내기도 한다.

        이러한 정성적인 데이터가 output에 0 or 1(like code; died:0 / survived:1)과 같은 특정 결과로 나타나기도 한다.


* Qunatative variable

* Ordred Categorical

    각 Qualitative한 데이터에 대하여 순서를 띄는 경우를 말한다. (e.g. 대/중/소)

### problem definition type by data type

* Classification / Regression

    예측해야 할 결과 값에 따라 prediction problem의 명명이 달라진다. 일반적으로는 아래와 같이 분류한다.
* 'Classification': 정성적인 결과값을 예측하는 문제 
* 'Regression': 정량적인 결과값을 예측하는 문제

결과적으로 Classification이던 Regression이던 **function approximation**의 방법으로 추정가능하기 때문에 유사하게 접근 가능하다.

### Symbols for Input / Output

* X: Inputs (N rows, p vectors; NXp Matrix)
* Y: Quantative Outputs ($\hat{Y}$: prediction for output Y)
* G: Qualitative Outputs($\hat{G}$: prediction for output G)

## 2.3. Two Simple Approaches to Prediction: Least Squares and Nearest Neighbors

prediction method about
* linear model(by least squares)
* k-nearest neighbor prediction

### 2.3.1. Linear Models and Least Squares

Linear Model은 구조와 산출값이 안정적이라는 제약을 가하지만 잘못된 예측이 될 수 있는 방법이다.

<div align="center">
<img src="imgs/eq_2_1.jpg">
</div>

<div align="center">
<img src="imgs/eq_2_2.jpg">
</div>

Input X의 1열 p열까지의 feature![formular](https://render.githubusercontent.com/render/math?math=X^{T}=(X_1,X_2,...,X_p))에 대해 output Y값을 예측하기 위한 식은 위와 같다. ![formular](https://render.githubusercontent.com/render/math?math=\hat{\beta}_0)는 intercept(계수)이고, ML에서는 bias(편차)라고 불린다. 이를 간편히 표현하기 위해 ![formular](https://render.githubusercontent.com/render/math?math=\hat{\beta}_0)에 대응되는 input X를 1로 대응시키면 두번째 수식이된다.

Linear Model을 훈련 데이터를 통해 학습하는 방식 중의 대표적인 방법은 *least squares* 방식을 활용하는 것이다. 아래의 RSS(residual sum of square)를 최소로하는 계수(beta)값을 찾는 것이다.

<div align="center">
<img src="imgs/eq_2_3.jpg">
</div>

RSS를 beta에 대한 2차식으로 볼 수 있고, 이를 최소화하는 beta를 계산하기 위해 미분을 수행한다.

RSS를 beta 측면에서 보면 2차식이기 때문에 최소로 하는 점은 항상 존재한다. RSS를 전치행렬과의 내적으로 표현할 수 있다. 그리고 RSS의 unique한 값을 찾기 위해 RSS를 beta에 대해 미분하면 두 번째 식이 나타난다.

<div align="center">
<img src="imgs/eq_2_4.jpg"></br>
<img src="imgs/eq_2_5.jpg">
</div>

그리고 ![formular](https://render.githubusercontent.com/render/math?math=X^T{X})가 <a href="https://datacookbook.kr/81"> 역행렬을 취할수 있는 nonsingular(정칙행렬)</a>이라면 RSS를 최소화하는 unique한 계수(beta) 값을 아래와 같이 나타낼 수 있다.

<div align="center">
<img src="imgs/eq_2_6.jpg">
</div>

<div align="center">
<img src="imgs/proof_2_1.jpg">
</div>

<div align="center">
<img src="imgs/fig_2_1.jpg">
</div>

결과 분포를 살펴보면 일부 잘못 분류된 값들을 볼 수 있다. 만약 linear model에 가해지는 제약이 더 많다면 error를 줄일 수 있었을까?

#### Question

* Senario 1.

    훈련에 사용되는 데이터셋이 상호 feature들 간에 상관관계가 없고 다른 평균을 가지는 Gaussian 분포라면?

* Senario 2.

    훈련 데이터셋이 작은 분산을 가지는 10개의 Gaussian 분포의 혼합이며, 각각의 평균들이 Guassian 분포를 따르는 경우.

### 2.3.2. Nearest Neighbor Method

Least Square 방식에 비해 상대적으로 구조적인 제약이 덜한 방식.

Nearest neighbor 방식은 훈련셋 T의 관측치들을 활용하여 Y hat의 형태로 변환하여 오차를 줄여나가는 방식이다.

<div align="center">
<img src="imgs/eq_2_8.jpg">
</div>

![formular](https://render.githubusercontent.com/render/math?math=N_k(x))는 샘플 내 특정 포인트 x에 인접한 k개의 이웃 포인트들을 말한다. 

<div align="center">
<img src="imgs/fig_2_2.jpg">
</div>

<div align="center">
<img src="imgs/fig_2_3.jpg">
</div>

k nearest neighbor의 계수의 개수에 따라서 decision boundary가 변화하는 것을 볼 수 있다. 15인 경우에는 Linear Model을 사용한 것보다 더 잘나타내는 것 같으며, 1인 경우에는 더 상세하게 구분하면서도 misclassification하는 경우가 발생하지 않는다.

### 2.3.3 From Least Squares to Nearest Neighbors

* Linear Model: 의사결정경계가 선형적인 것을 가정하고 예측을 위한 parameter(계수)를 학습한다. (low variance / high bias) 

* Nearest Neighbor: Linear Model과 달리, 사용하는 데이터에 어떤 제약사항도 없기 때문에 어떤 상황에서도 활용가능한 방법. 그러나 결정경계의 특정 지점은 input 데이터에 따라 불안정하다. (high variance / low bias)


## 2.4. Statistical Decision Theory

![formular](https://render.githubusercontent.com/render/math?math=X\in{R^p})는 random input vector로, Y는 ![formular](https://render.githubusercontent.com/render/math?math=Y\in{R})을 만족하고 ![formular](https://render.githubusercontent.com/render/math?math=Pr(X,Y)) 값을 가지는 vector로 나타낸다. 정의를 바탕으로 input X를 받아 Y를 예측하는 함수 ![formular](https://render.githubusercontent.com/render/math?math=f(x))를 찾는 것이 목적이다. 이를 위해, loss function ![formular](https://render.githubusercontent.com/render/math?math=L(Y,f(X)))를 찾는것이 중요하고 sqaured error loss ![formular](https://render.githubusercontent.com/render/math?math=L(Y,f(X))=(Y-f(X))^2)를 활용한다.

<div>
<img src="imgs/eq_2_9_10.jpg"/></br>
<img src="imgs/eq_2_11.jpg"/></br>
<img src="imgs/eq_2_12.jpg"/></br>
<img src="imgs/eq_2_13.jpg"/>
</div>

EPE를 계산함에 있어, 확률변수 Y의 기대값을 계산하는 것이다. 확률변수 Y의 기대값을 구하는데 있어서 조건부 확률밀도함수를 사용하여 계산하는 방법의 식을 정리하면 위와 같다.

EPE를 확률밀도함수의 정의로 변환하고, EPE를 최소화하게 되면, 목표로 하는 함수 f(x)가 예측을 잘하는 것이다. 따라서 argmin을 수행한다. 결과적으로 X=x일때의 Y가 이 값을 최소로 만들게 된다.

<div align="center">
<img src="imgs/proof_2_2.jpg" />
</div>

nearest neighbor에 대해서도 같은 접근 법으로 식을 간단히 하게 되면.

<div>
<img src="imgs/eq_2_14.jpg" />
</div>

'Ave'는 평균을 나타내고, Nk(x)는 k지점에 인접한 데이터들의 집합을 나타낸다.

위와 같이 나타내는데 있어 두가지 가정이 존재한다.
* 기대값은 샘플데이터들의 평균으로 근사
* 한 포인트에 맞춰진다는 것은 그 포인트에 
가까워진다는 것을 의미

data size N과 neighbor size k에 대해 N이 크면 특정 포인트 x에 대해 많은 이웃들이 있게되고, k값이 클 수록 평균값은 더 안정적이게 된다. 따라서 N과 k가 크면 클수록 linear model에서 정의했던 EPE를 최소화하기 위한 y hat에 대한 식과 동일해진다.

<img src="imgs/eq_2_13.jpg" />

만약 두 방법에 대해서 고차원 데이터셋이 활용되는 경우에는 어떻게 할것인가?

linear regression에서는 

<img src="imgs/eq_2_15.jpg" />
<img src="imgs/eq_2_16.jpg" />

위와 같이 f(x)식을 가정하여 모델링 한 후 계수 beta를 구할 수 있다.

결과적으로, least square와 nearest neighbor방식 모두 평균에 의해 조건부 기대값으로 추정했다(least square의 경우 모든 확률변수 X에 대한 Y의 기대값은 산술적인 평균과 유사하기 때문). 그러나 각각은 모델의 가정이 다르다.

* Least Sqaure: f(x)는 전역적으로 선형적인 함수를 띈다. - model-based
* Nearest Neighbor: 지역적인 상수함수에 의해 추정된다.

Nearest Neighbor방식이 더 간단하여 채택하기 좋아보이지만, "flexibility"를 위한 비용(범용성있는 모델을 사용하는)을 지불(가정을 부여)해야 한다.

가정을 부여하는 것에 대한 예시를 rigid linear model에 대응하여 살펴보자.

<img src="imgs/eq_2_17.jpg" />

이는 선형모델에 <a href="https://stat.snu.ac.kr/heeseok/teaching/asm17/regression1-%EB%B0%9C%ED%91%9C.pdf">additivity 제약(가법성 가정)</a>을 부여했다. 

#### **가법성 가정**

반응변수에 대한 예측변수(Xj)의 효과는 다른 예측변수들의 값에 영향을 받지 않는다.

고차원 데이터를 가진 환경에서 조건부 기대값을 추정하는 문제를 위해서는 모델에 대해 임의의 제약을 추가해야 한다(such as additivity). 


Loss를 계산하는데 있어 2.11의 제곱을 활용한 L2 규제가 아닌, 절대값을 활용한 L1규제를 활용하면 어떻게 될까?

L1 규제는 L2규제 방식보다 더 탄탄하지만, 각 예측변수들의 도함수들이 불연속적으로 가정하기 떄문에 잘 사용되지 못한다.

<div>
<img src="imgs/eq_2_18.jpg" />
</div>

### **categorical variable G**

다루는 model의 output이 카테고리 특성을 지닌 값이라면 어떻게 될까? 이를 위해 다른 loss function을 사용해야 한다. 

loss function은 K(G의 unique한 개수; 기수성) X K 행렬인 L로 나타낸다. L은 대각행렬에 대해서는 0이고, 모든 값들은 0이상의 값을 가진다. 그리고 L(k,l)은 관측치 class k를 l에 속하게 하는데 있어 지불하는 비용을 뜻한다. 그리고 loss를 산정함에 있어서 하나의 예측값(single unit)에 대한 misclassification을 측정하는 zero-one loss function을 활용한다. 따라서 이에 대한 EPE는 아래와 같이 나타낼 수 있다.

<img src="imgs/proof_2_3.jpg" />


이를 위해 가장 적절한 방법은 conditional distribution Pr(G|X)를 활용하여 가장 가능한 클래스를 분류하는 '베이즈 분류기'를 사용하는 것이다.

**Bayes Classifier**

어떤 분류 문제에서, 사전확률 P(C1),P(C2)만 알고 있을때  어떻게 가장 합리적인 판단을 할 수 있을까? 그떄는 상대적으로 높은 확률을 지닌 클래스를 선정하는 것이다.

그러나 문제는 이 결정에 대한 error는 항상 0.4이고 classification result는 항상 C1이 될 것이다. 그래서 이를 더 발전시키기 위해서는 다른 정보 또한 필요하다.

우리가 목표로 추구하는 데이터 X에 대한 클래스를 분류하는 확률 P(C1|X),P(C2|X)은 likelihood에 대한 정보를 가지고 있다면 더 발전할 수 있다. 이 정보를 알고 있다면 베이즈 정리에 의해 P(C1|X),P(C2|X)를 구할 수 있기 때문이다.

<img src="imgs/bayes_rule.jpg" />

특정 sample Xi에 대해서 어떤 class를 택할지는 아래와 같이 나타낼 수 있게 된다.

<img src="https://latex.codecogs.com/svg.latex?C=argmaxP(C|X)=argmax\frac{P(X|C)P(C)}{\sum_{i}P(X|C_i)P(C_i)}" title="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" />

## 2.5 Local Methods in High Dimensions

위에서 살펴본 대표적인 2가지 prediction model
* stable: 'biased Linear model'
* less stable: 'less biased class of k-nearest neighbor'

NN방식으로 최적의 조건부 평균을 찾을 수 있는 이유는 관측치에서 neighbor의 수를 크게 잡기 때문이다. 그러나 이는 고차원으로 확장되는 순간 무너진다. 이를 차원의 저주라고 하며, 이로 인해 발생하는 문제점들을 살펴보도록 하자.

### sparse sampling

1. 이웃들간의 거리가 점차 증가하는 현상

    NN에 사용되는 uniformly distributed input을 p차원의 hypercube의 형태로 나타내면 아래의 그림과 같다. 그리고 관측치들의 일부 r을 포착하기 위해 target point에 대한 표현을 hypercubial 하게 나타내자. 이는 단위 부피의 r 파편으로 대응되어 expected edge의 길이를 ![formular](https://render.githubusercontent.com/render/math?math=e_p(r)=r^{1/p})로 나타낼 수 있다.

    1% or 10%의 데이터를 local average 핼태로 나타내면 전체 input data의 63% or 80% 정도만을 커버하게 되므로 더이상 이웃들이 "local"하다고 할 수 없게 된다. 따라서, avg하는데 있어서 수행하는 sample의 수가 작으면 학습시에 variance가 커진다는 것을 알 수 있다.

2. sample point가 edge of sample point로 퍼지는 현상

    N data point를 p차원의 단위 구에 원점으로부터 uniform distribute하게 나누어 두었다고 하자. 그리고 origin에서부터 nearest neighbor를 추정한다고 가정했을때, 원점에서부터 각 data point까지의 거리는 아래와 같이 계산할 수 있다.

    <img src="imgs/eq_2_24.jpg"/>

    i.e) N=500, p=10, d(p,N) ~ 0.52; 따라서, 대부분의 data point가 다른 data point에 비해 sample space의 경계에 더 가까이 있음을 알수 있다. 이때문에, 경계 근처에 있는 training sample에 대해서는 예측이 더 어려워질 수밖에 없다(via extra/interpolate). 

3. sampling density의 변화 (to, ![formular](https://render.githubusercontent.com/render/math?math=N^{1/p}))

    if, single input problem에 대해 100개의 dense sample이 필요하다고 하자. 이를 10개의 input problem에 10개의 차원으로 확장한다면, 100의 10승개의 dense sample이 필요하게 된다. 따라서 고차원에서는 학습에 필요한 샘플들이 input공간을 sparse하게 채우게 된다. 

    <div>
    <img src="imgs/eq_2_25.jpg"/>
    </div>

    위의 수식은 임의의 nearest neighbor문제에 대해 x0일때의 f(0)를 추측하기 위한 MSE 수식이다.

    <div>
    <img src="imgs/fig_2_7.jpg"/>
    </div>

    MSE문제를 Variance와 Squared bias로 나누어 Fig 2.7을 참고하여 살펴보자. 이를 'bias-variance decomposition'이라고 하는 유용한 접근 법이다. 위에서 variance는 1-nearest neighbor임으로 N(sample size)가 1000이면 Error는 bias와 variance모두 작기 때문에 0과 밀접하게 가까워질 것이다.  

    차원이 커질수록 NN은 target point에서 점점 멀어지는 경향이 있어 bias와 variance는 모두 증가하게 된다. p가 10일때는 샘플 중에 99%가 원래 지점보다 0.5 distance이상 멀어져있게 된다. 따라서 p값이 증가하면 추정치는 0이 될 것이며, p값이 감소한다면 MSE level은 분산과 마찬가지로 1.0에서 덜어지며 vairance도 떨어질 것이다.

예제들이 극단적이지만, 일반적으로 살펴보자. 많은 변수를 가진 함수가 복잡해지는 것은 차원의 복잡도를 높이는 것과 동일하다. 그런데도 낮은 차원에서 학습시키는 것과 동일한 수준의 결과를 얻으려면 학습에 사용되는 데이터셋도 그와 같이 많아져야한다.

위의 2.7. 예제의 function을 linear한 함수에 대해 예제를 변환하여 살펴보자.

우선, (2.25)의 x0에 대한 MSE식에 Y를 (2.26)의 식으로 대체하자. 

<img src="imgs/eq_2_26.jpg"/>

linear model에서 X값을 최소로 하는 계수를 계산할때, 계수는 (2,6)의 식과 같이 나타남을 알 수 있었다. 

<img src="imgs/eq_2_6.jpg" />

해당 식에 (2.26)의 y에 식을 적용한다.
 
<img src="imgs/proof_2_4.jpg" />

그렇게 되면 예측되는 계수(beta hat)는 위와 같아지며, 계산한 beta hat을 임의의 x0와 y hat 0의 식에 대입하면 y hat 0를 이와같이 나타낼 수 있고, 이렇게되면 y와 y hat의 기대값이 Xbeta로 동일해진다.

y와 y hat의 기대값이 값다는 것을 가지고 x0에 대해 EPE를 계산할 수 있게 된다.

결과적으로 bias는 EPE에 전혀 영향을 미치지 않고 variance만 분포의 표준편차에 의해 영향을 받는것을 알 수 있다.

<div>
<img src="imgs/fig_2_8.jpg">
</div>

추가적으로 N이 크고 T가 랜덤한 방식으로 추출되면 E(X)=0이고 i컬럼과 j컬럼 간에는 상관관계가 없으며 둘 간의 분산이 동일하면.XTX -> NCov(X)로 변환할 수 있게 된다.

<img src="https://latex.codecogs.com/svg.latex?(1/N)X^TX=Cov(X)=\sigma_x^2{I_p}"
 title="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" />

<img src="imgs/eq_2_28.jpg"/>

(2.28)식에 의해 EPE의 기대값은 차원 parameter p에 의해 sigma^2/N 만큼 선형적으로 증가함을 알 수 있다. N이 크고 sigma^2이 작다고 가정하였기 떄문에 variance가 증가하는 것은 무시 가능하다. 

이렇게 강력한 제약들을 가함으로써 차원의 저주를 극복할 수 있게 된다.

1-NN의 식을 Least Sqaure방식으로 loss를 산정할때 대상 식 f(x)를 1차식과 3차식으로 적용했을 때 차원의 변화에 따른 EPE값의 변화 추이를 보자.

<img src="imgs/fig_2_9.jpg" />

## 2.6. Statistical Models, Supervised Learning and Function Approximation

목표는 input과 output을 활용하여 f(x)에 더 가까운 근사를 하는 f(x) hat을 추정하는 것이다. linear model에서 결과적으로 추론한 regression function은 모든 데이터 X에 대하여 얻을 수 있는 기대값으로 나타난다. 그리고 nn방식에서도 조건부 기대값을 활용하여 추정할 수 있었다.

그러나 이는 아래의 두 상태에서는 불가능하다.

1. Input space의 차원이 너무커서, nn이 target point에 근접하지 못하는 경우 큰 error를 만들 수 있다.

2. bias와 variance를 동시에 줄이는 special structure를 찾은 경우

해당 챕터에서는 차원의 문제를 극복할 수 있는 방법을 prediction problem에 적용하여 살펴본다.

### 2.6.1. Statistical Model from the Joint Distribution Pr(X,Y)

<div>
<img src="imgs/eq_2_29.jpg">
</div>

데이터가 위와 같은 통계적 모델을 통해 나타난다고 가정하자. 그리고, ![formular](https://render.githubusercontent.com/render/math?math=f(x)=E(Y|X=x)) 이며, f(x)의 조건부 평균을 나타내는데 있어 Pr(Y|X)는 X에 대해 전제를 우선한다.

addtive model(오차를 더하는 모델)은 추정하는데 유용하다. 대부분의 모델이 (X,Y)의 pair에 대해 절대적으로 Y=f(x)의 관계를 가지지 않기 떄문이다. 일반적으로 Y에 기여하는 measurment error가 있다는 것이다. addictive model은 이러한 내용을 e로 나타내는 것이다.

(2.29)식에서 error가 i.i.d라는 가정은 무조건 필요로 하지 않지만, EPE의 가정 중에 squared error를 일정하게 average하는 가정을 떠올리게 한다. 이렇게 uniform average한 가정이 model estimation에 있어 (2.1)의 수식을 활용하게 하는 것이다.

quantative response를 더 다뤄보면, Additive error는 qualitative output G에는 활용되지 않는다. qualitative 문제에서 p(X)는 Pr(G|X)를 활용하여 나타낸다.

### 2.6.2. Supervised Learning

Y=f(X)+e라는 형태를 가진 수식에서 지도학습은 (x1,y1),...,(xn,yn)의 결과값을 가지고 x값을 학습에 투입함으로써 알고리즘을 학습시킨다. 그리고 f(xi) hat을 반응으로 생성하고 실제값과의 오차를 활용하여 이를 줄여나가며 결과적으로 실제로 다른 데이터에서도 이 오차가 줄어들 수 있도록 학습한다.

### 2.6.3. Function Approximation

2.6.2. 절의 approach를,

* to, ML and AI - supervised learning
* to, math and stats - function approximation and estimation

p+1 차원의 유클리디안 공간에 {xi,yi} data point를 나타내면, function f(x)에 의해 yi=f(xi)+ei로 매핑할 수 있다. domain은 p차원의 유글리디안 공간 R^p에 나타난다. Function Approximation의 목표는 R^p의 모든 x에 대해 적절한 f(x) approximation을 하는 것이다.

function approximation 방식은 유클리디안 공간의 위치적인 개념과 확률 추론의 수학적인 개념을 문제에 적용하는 것이다.

확률 추론에서 조정해야할 파라미터 Theta는 데이터에 따라서 수정된다. 예를들어 linear model에서의 파라미터 Theta는 계수(beta)가 되는 것이다.

<div>
<img src="imgs/eq_2_30.jpg">
<img src="imgs/eq_2_31.jpg">
<img src="imgs/eq_2_32.jpg">
</div>

hk는 input vector에 가하는 function 또는 변환의 set을 말하며, 다양한 것들이 있지만 nonlinear expansion에 대해서는 sigmoid transformation을 들 수 있다.

그리고, apporximation해야하는 f의 파라미터 Theta를 추정하기 위해서 linear model은 RSS를 활용한다.

<img src="imgs/fig_2_10.jpg">

p=2인 차원에 대응하는 데이터로 f(x)를 표현하면 위의 그림과 같이 나타난다. additive noise에 의한 output noise 좌표는 그림과 같이 나타난다. 그리고 가능한 관측치에서 가까운 학습된 표면을 통해 파라미터 set을 찾아낸다. 이때 closeness를 판별하는 지표가 RSS이다.

RSS가 간편한 방법이긴 하지만 모든 상황에 들어맞는 유일한 criterion은 아니다. 추정을 위한 일반적인 방법론은 'maximum likelihood estimation'이다.

<img src="imgs/eq_2_33.jpg"/>

'maximum likelihood estimation'의 가정은 reasonable한 Theta값이 관측된 샘플들의 확률들 중에서 가장 크다는 것이다(평균을 나타내는 것?). 'maximum likelihood estimation'에서는 Least Sqaure 방식과 같은 오차를 최소화하는 식을 아래와 같이 나타낼 수 있다.

<img src="imgs/eq_2_34.jpg"/>

이는 예측한 값을 평균으로 하고, sigma를 표준편차로하는 분포로 나타내는 것과 동일하다.


#### Maximum Likelihood Estimation

만약, 키를 가지고 몸무게를 예측해야 하는 문제를 받았다고 생각하자. 이를 위해 parameter w를 가지고 키를 넣으면 몸무게를 반환하는 함수 y(x|w)함수를 정의할 수 있으며, 이것이 실제값과 가깝게 나오도록 w를 조정해야 한다. 파라미터 w는 회귀식의 계수와 편향을 모두 합쳐서 부를 수 있다.

<img src="https://latex.codecogs.com/svg.latex?t=y(x|w)" title="t=y(x|w)" />

그러나 우리의 예측값 y(x|w)는 실제값 t와 완전히 같다고 말할 수 없다. 따라서 t를 표현하기 위해 수학적으로 아래와 같이 표현할 수 있다.

"실제 몸무게(t)는 random variable이며, 예측한 몸무게 y를 평균으로 하며 특정값 sigma를 표준편차로 하는 '정규분포'를 따른다고 표현할 수 있다."

<img src="https://latex.codecogs.com/svg.latex?t\sim{N}(y(x|w),\sigma^2)" title="t\sim{N}(y((x|w)),\sigma^2)" /></br>

위의 말은 y(x|w)를 평균으로, sigma를 표준편차로하는 분포를 나타내는 식으로 표현할 수 있으며,

<img src="https://latex.codecogs.com/svg.latex?p(t|x,w,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" title="p(t|x,w,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" />

이는 위의 식과 같은 수식으로 나타낼 수 있다.

w와 sigma는 parameter이기 때문에 식을 아래와 같이 생략하여 표현한다.

<img src="https://latex.codecogs.com/svg.latex?p(t|x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" title="p(t|x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" />

p(t|x)는 키가 x일때, 실제 몸무게가 t일 확률을 말한다. 주어진 모든 데이터 D의 데이터포인트들에 대해 수식을 나타내면 아래와 같다(모든 데이터 포인트들은 독립이라고 가정). 

<img src="https://latex.codecogs.com/svg.latex?p(D)=\overset{N}{\underset{i=1}{\prod}}p(t_i|x_i)=\overset{N}{\underset{i=1}{\prod}}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" title="p(D)=\overset{N}{\underset{i=1}{\prod}}p(t_i|x_i)=\overset{N}{\underset{i=1}{\prod}}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(t-y(x|w))^2}{2\sigma^2}}" />

위의 수식을 살펴보았을때, 모든 Data point에 대한 확률은 parameter w에 따라 달라질 수 있음을 알 수 있다. 따라서 이를 p(D|w)로 나타낼 수 있다.

결국 우리가 예측해야 하는 모델은 모든 데이터포인트들에 대응되는 p(D|w)를 최대로 하는 모델이다. 그리고 이 때의 w를 찾아야 한다. 여기서 p(D|w)이며, 이 방식을 Maximum Likelihood Estimation이라고 한다.

**그렇다면 왜 log를 취하는 것일까??**

이는 계산의 용이성을 위함이다.

<img src="https://latex.codecogs.com/svg.latex?loglikelihood=log(p(D|w))=\overset{N}{\underset{i=1}{\sum}}{-log(\sqrt{2\pi}\sigma)-\frac{(t_i-y(x_i|w))^2}{2\sigma^2}}" title="loglikelihood=log(p(D|w))=\overset{N}{\underset{i=1}{\sum}}{-log(\sqrt{2\pi}\sigma)-\frac{(t_i-y(x_i|w))^2}{2\sigma^2}}" />

기존 likelihood estimation에 log를 취해도 크기상의 문제는 발생하지 않는다. 그리고 log를 취함으로써 production 연산을 summation 연산으로 바꿀 수 있다. 그리고 위의 식에서 sigma와 pi는 상수 값이므로 최대화 해야하는 대상만을 정리하면 아래와 같다.

<img src="https://latex.codecogs.com/svg.latex?\underset{i=1}{\overset{N}{\sum}}(t_i-y(x_i|w))^2" title="\underset{N}{\overset{i=1}{\sum}}(t_i-y(x_i|w))^2" />

그리고 위의 식은 예측 값과 실제 값의 차이의 제곱 L2 Loss이다. 따라서, MLE를 최대화한다는 것은 실제값과 예측값의 오차를 줄인다는 것과 동일한 의미임을 알 수 있다.

## 2.7 Structured Regression Models

### 2.7.1. Difficulty of the Problem

<img src="imgs/eq_2_37.jpg" />

위의 RSS를 최소화하는 function을 학습하는데 있어서 train case에 수행했던 것과 달리 test case에서는 poor predicator가 되는 경우가 있다.


## 2.8. Classes of Restricted Estimator

'smoothing parameter'(근접 이웃들의 수를 조절하는)

### 2.8.1. Roughness Penalty and Bayesian Methods

<img src="imgs/eq_2_38.jpg">

RSS(f) function은 임의의 function J에 의해 "Roughness Penalty"를 받게 된다. 왜 이러한 페널티를 주는지 책의 예제로 살펴보자.

<img src="imgs/eq_2_39.jpg"/>

예제의 function은 'cumic smoothing spline'이다. 이를 least-sqaure 방식에 도입한 수식은 위와 같다.

특정 함수의 1차 도함수는 기울기


f(x)의 이중 도함수에 의헤 페널티의 강도가 결정됨. 이를 bayesian framework에 도입할 수 있으며,

J: log-prior
PRSS: log-posterior

## 2.9 Model Selection and Bias-Variance Trade off

모든 모델은 아래의 고려조건을 반영한 smoothing / complexity parameter를 가진다.

* the multiplier of the penalty term
* the width of the kernel
* the number of basis functions

lambda index가 interpolating model이 직선에 가깝도록 제약을 건다.

유사하게 local degree-m 다항식 모델의 범위를 window 사이즈가 무한대로 커지게 만들면 interpolating이 윈도우 크기를 0로 줄임으로써 fit한다.

파라미터를 결정하는데 있어서 RSS를 사용할수 없음을 말함. 0의 잔차임에도 interpolatinc fit을 하는 방안으로 선택해야함. 이런 모델은 추후의 데이터에 대해 표현을 하지 못함.

<img src="imgs/eq_2_46_47.jpg">

* sigma square: irreducible error - 새 테스트 데이터셋의 분산
* mean squard error of fk(x0) hat - bias / variance로 구분
    * variance(avg of var): k값과 avg of var은 반비례.


<img src="imgs/fig_2_11.jpg">