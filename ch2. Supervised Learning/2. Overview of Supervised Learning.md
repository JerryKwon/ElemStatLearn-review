# 2. Overview of Supervised Learning

## Reference

* RSS 미분

    <a href="https://math.stackexchange.com/questions/2387495/how-do-you-differentiate-a-matrix-equation-with-respect-to-a-vector">https://math.stackexchange.com/questions/2387495/how-do-you-differentiate-a-matrix-equation-with-respect-to-a-vector</a>


* eq_2.9-2.13

    <a href="https://kitech.tistory.com/6?category=793139">https://kitech.tistory.com/6?category=793139</a>

* 조건부평균

    <a href="https://datascienceschool.net/02%20mathematics/07.06%20%EC%A1%B0%EA%B1%B4%EB%B6%80%EA%B8%B0%EB%8C%93%EA%B0%92%EA%B3%BC%20%EC%98%88%EC%B8%A1%20%EB%AC%B8%EC%A0%9C.html">https://datascienceschool.net/02%20mathematics/07.06%20%EC%A1%B0%EA%B1%B4%EB%B6%80%EA%B8%B0%EB%8C%93%EA%B0%92%EA%B3%BC%20%EC%98%88%EC%B8%A1%20%EB%AC%B8%EC%A0%9C.html</a>

## 2.1. Introduction

input값을 통해 output값을 예측하는 일련의 과정인 'supervised learning'(지도학습)에 대해 알아보자.

## 2.2. Variable Types and Terminology

### type of variables

* Qualitative variable

    각 결과값들 간의 순서가 존재하지 않으며, 숫자나 값이 class 형태로 사용되는 경우. 이를 'categorical' or 'discrete'하다고 한다.

    * Usage for Input / output

        Input으로는 다차원의 categorical한 정보를 담기도 하는데, 이를 위해서 K-level한 변수를 각 컬럼으로 나누는 dummy variable을 생성하여 나타내기도 한다.

        이러한 정성적인 데이터가 output에 0 or 1(like code; died:0 / survived:1)과 같은 특정 결과로 나타나기도 한다.


* Qunatative variable

* Ordred Categorical

    각 Qualitative한 데이터에 대하여 순서를 띄는 경우를 말한다. (e.g. 대/중/소)

### problem definition type by data type

* Classification / Regression

    예측해야 할 결과 값에 따라 prediction problem의 명명이 달라진다. 일반적으로는 아래와 같이 분류한다.
* 'Classification': 정성적인 결과값을 예측하는 문제 
* 'Regression': 정량적인 결과값을 예측하는 문제

결과적으로 Classification이던 Regression이던 **function approximation**의 방법으로 추정가능하기 때문에 유사하게 접근 가능하다.

function approximation

<a href="https://machinelearningmastery.com/neural-networks-are-function-approximators/">https://machinelearningmastery.com/neural-networks-are-function-approximators/</a>



### Symbols for Input / Output

* X: Inputs (N rows, p vectors; NXp Matrix)
* Y: Quantative Outputs ($\hat{Y}$: prediction for output Y)
* G: Qualitative Outputs($\hat{G}$: prediction for output G)

## 2.3. Two Simple Approaches to Prediction: Least Squares and Nearest Neighbors

prediction method about
* linear model(by least squares)
* k-nearest neighbor prediction

### 2.3.1. Linear Models and Least Squares

Linear Model은 구조와 산출값이 안정적이라는 제약을 가하지만 잘못된 예측이 될 수 있는 방법이다.

<div align="center">
<img src="imgs/eq_2_1.jpg">
</div>

<div align="center">
<img src="imgs/eq_2_2.jpg">
</div>

Input X의 1열 p열까지의 feature![formular](https://render.githubusercontent.com/render/math?math=X^{T}=(X_1,X_2,...,X_p))에 대해 output Y값을 예측하기 위한 식은 위와 같다. ![formular](https://render.githubusercontent.com/render/math?math=\hat{\beta}_0)는 intercept(계수)이고, ML에서는 bias(편차)라고 불린다. 이를 간편히 표현하기 위해 ![formular](https://render.githubusercontent.com/render/math?math=\hat{\beta}_0)에 대응되는 input X를 1로 대응시키면 두번째 수식이된다.

Linear Model을 훈련 데이터를 통해 학습하는 방식 중의 대표적인 방법은 *least squares* 방식을 활용하는 것이다. 아래의 RSS(residual sum of square)를 최소로하는 계수(beta)값을 찾는 것이다.

<div align="center">
<img src="imgs/eq_2_3.jpg">
</div>

RSS를 beta에 대한 2차식으로 볼 수 있고, 이를 최소화하는 beta를 계산하기 위해 미분을 수행한다.

RSS를 beta 측면에서 보면 2차식이기 때문에 최소로 하는 점은 항상 존재한다. RSS를 전치행렬과의 내적으로 표현할 수 있다. 그리고 RSS의 unique한 값을 찾기 위해 RSS를 beta에 대해 미분하면 두 번째 식이 나타난다.

<div align="center">
<img src="imgs/eq_2_4.jpg"></br>
<img src="imgs/eq_2_5.jpg">
</div>

그리고 ![formular](https://render.githubusercontent.com/render/math?math=X^T{X})가 <a href="https://datacookbook.kr/81"> 역행렬을 취할수 있는 nonsingular(정칙행렬)</a>이라면 RSS를 최소화하는 unique한 계수(beta) 값을 아래와 같이 나타낼 수 있다.

<div align="center">
<img src="imgs/eq_2_6.jpg">
</div>

<div align="center">
<img src="imgs/proof_2_1.jpg">
</div>

<div align="center">
<img src="imgs/fig_2_1.jpg">
</div>

결과 분포를 살펴보면 일부 잘못 분류된 값들을 볼 수 있다. 만약 linear model에 가해지는 제약이 더 많다면 error를 줄일 수 있었을까?

#### Question

https://stats.stackexchange.com/questions/81197/can-someone-please-explain-to-me-what-the-particular-scenarios-mean

* Senario 1.

    훈련에 사용되는 데이터셋이 상호 feature들 간에 상관관계가 없고 다른 평균을 가지는 Gaussian 분포라면?

* Senario 2.

    훈련 데이터셋이 작은 분산을 가지는 10개의 Gaussian 분포의 혼합이며, 각각의 평균들이 Guassian 분포를 따르는 경우.

### 2.3.2. Nearest Neighbor Method

Least Square 방식에 비해 상대적으로 구조적인 제약이 덜한 방식.

Nearest neighbor 방식은 훈련셋 T의 관측치들을 활용하여 Y hat의 형태로 변환하여 오차를 줄여나가는 방식이다.

<div align="center">
<img src="imgs/eq_2_8.jpg">
</div>

![formular](https://render.githubusercontent.com/render/math?math=N_k(x))는 샘플 내 특정 포인트 x에 인접한 k개의 이웃 포인트들을 말한다. 

<div align="center">
<img src="imgs/fig_2_2.jpg">
</div>

<div align="center">
<img src="imgs/fig_2_3.jpg">
</div>

k nearest neighbor의 계수의 개수에 따라서 decision boundary가 변화하는 것을 볼 수 있다. 15인 경우에는 Linear Model을 사용한 것보다 더 잘나타내는 것 같으며, 1인 경우에는 더 상세하게 구분하면서도 misclassification하는 경우가 발생하지 않는다.

### 2.3.3 From Least Squares to Nearest Neighbors

* Linear Model: 의사결정경계가 선형적인 것을 가정하고 예측을 위한 parameter(계수)를 학습한다. (low variance / high bias) 

* Nearest Neighbor: Linear Model과 달리, 사용하는 데이터에 어떤 제약사항도 없기 때문에 어떤 상황에서도 활용가능한 방법. 그러나 결정경계의 특정 지점은 input 데이터에 따라 불안정하다. (high variance / low bias)


## 2.4. Statistical Decision Theory

![formular](https://render.githubusercontent.com/render/math?math=X\in{R^p})는 random input vector로, Y는 ![formular](https://render.githubusercontent.com/render/math?math=Y\in{R})을 만족하고 ![formular](https://render.githubusercontent.com/render/math?math=Pr(X,Y)) 값을 가지는 vector로 나타낸다. 정의를 바탕으로 input X를 받아 Y를 예측하는 함수 ![formular](https://render.githubusercontent.com/render/math?math=f(x))를 찾는 것이 목적이다. 이를 위해, loss function ![formular](https://render.githubusercontent.com/render/math?math=L(Y,f(X)))를 찾는것이 중요하고 sqaured error loss ![formular](https://render.githubusercontent.com/render/math?math=L(Y,f(X))=(Y-f(X))^2)를 활용한다.

<div>
<img src="imgs/eq_2_9_10.jpg"/></br>
<img src="imgs/eq_2_11.jpg"/></br>
<img src="imgs/eq_2_12.jpg"/></br>
<img src="imgs/eq_2_13.jpg"/>
</div>

EPE를 계산함에 있어, 확률변수 Y의 기대값을 계산하는 것이다. 확률변수 Y의 기대값을 구하는데 있어서 조건부 확률밀도함수를 사용하여 계산하는 방법의 식을 정리하면 위와 같다.

EPE를 확률밀도함수의 정의로 변환하고, EPE를 최소화하게 되면, 목표로 하는 함수 f(x)가 예측을 잘하는 것이다. 따라서 argmin을 수행한다. 결과적으로 X=x일때의 Y가 이 값을 최소로 만들게 된다.

<div align="center">
<img src="imgs/proof_2_2.jpg" />
</div>

nearest neighbor에 대해서도 같은 접근 법으로 식을 간단히 하게 되면.

<div>
<img src="imgs/eq_2_14.jpg" />
</div>

'Ave'는 평균을 나타내고, Nk(x)는 k지점에 인접한 데이터들의 집합을 나타낸다.

위와 같이 나타내는데 있어 두가지 가정이 존재한다.
* 기대값은 샘플데이터들의 평균으로 근사
* 한 포인트에 맞춰진다는 것은 그 포인트에 
가까워진다는 것을 의미

data size N과 neighbor size k에 대해 N이 크면 특정 포인트 x에 대해 많은 이웃들이 있게되고, k값이 클 수록 평균값은 더 안정적이게 된다. 따라서 N과 k가 크면 클수록 linear model에서 정의했던 EPE를 최소화하기 위한 y hat에 대한 식과 동일해진다.

<img src="imgs/eq_2_13.jpg" />

만약 두 방법에 대해서 고차원 데이터셋이 활용되는 경우에는 어떻게 할것인가?

linear regression에서는 

<img src="imgs/eq_2_15.jpg" />
<img src="imgs/eq_2_16.jpg" />

위와 같이 f(x)식을 가정하여 모델링 한 후 계수 beta를 구할 수 있다.

결과적으로, least square와 nearest neighbor방식 모두 평균에의해 조건부 기대값으로 추정했다. 그러나 각각은 모델의 가정이 다르다.

* Least Sqaure: f(x)는 전역적으로 선형적인 함수를 띈다.
* Nearest Neighbor: 지역적인 상수함수에 의해 추정된다.

Loss를 계산하는데 있어 2.11의 제곱을 활용한 L2 규제가 아닌, 절대값을 활용한 L1규제를 활용하면 어떻게 될까?



L2 규제를 적용한 (2.11)식을 L1 규제를 적용한 식으로 변형하면 어떻게 될까?

<div>
<img src="imgs/eq_2_18.jpg">
</div>

### categorical variable G

이를 위해 가장 적절한 방법은 conditional distribution Pr(G|X)를 활용하는 '베이즈 분류기'를 사용하는 것이다.

## 2.5 Local Methods in High Dimensions

* stable: 'biased Linear model'
* less stable: 'less biased class of k-nearest neighbor'

조건부평균을 활용하여 average로 nearest neighbor방식과 least square 방식을 나타내는것은 고차원으로 확장되는 순간 무너진다. ('차원의 저주')

차원의 저주 문제 1.

Since this corresponds to a fraction r of the unit volume,
the expected edge length will be ep(r) = r1/p. In ten dimensions e10(0.01) =
0.63 and e10(0.1) = 0.80, while the entire range for each input is only 1.0.
So to capture 1% or 10% of the data to form a local average, we must cover
63% or 80% of the range of each input variable. Such neighborhoods are no
longer “local.”

https://datapedia.tistory.com/15

fraction r을 낮춰봤자 차원의크기가 높다면 local하지 못하다.

고차원에서 sparse sampling 방식의 결과는 모든 sample 포인트들이 샘플의 edge와 가까워진다는 문제.

median distance로 측정해보았을때, boundary로 더 가까워진다는 사실을 확인.
이는 예측을 더 어렵게 만들기 때문에 큰 문제가 된다.

차원의 저주 문제 2.

샘플링 밀도의 변화. (to. ![formular](https://render.githubusercontent.com/render/math?math=N^{1/p}))

 차원의 크기가 클수록 같은 샘플의 수라도 차원이 낮은 수준의 샘플링 밀도를 맞추기 위해서는 더 많은 input이 필요하다.

<div>
<img src="imgs/eq_2_25.jpg">
</div>

위의 nearest neighbor 오차 계산식에서, 차원의 수가 점점 늘어날 수록, target point에서 점차 멀어지기 시작한다. 따라서 variance와 bias가 점차 늘어나는 것이다.

차원의 수가 10만늘어나도 99%의 샘플이 원래값보다 0.5 distance가 멀어져있다.

**차원의 수가 늘어날 수록 이를 충족시켜야하는 샘플의 수가 많아져야 한다는 것.**

for nearest neighbor

<div>
<img src="imgs/fig_2_7.jpg">
</div>

for least square

<div>
<img src="imgs/eq_2_27.jpg"></br>
<img src="imgs/eq_2_28.jpg">
</div>

차원 p는 \sigma^2 / N의 경사로 증가하고, N이 엄청나게 크고 sigma가 작다면, 차원의 증가는 무시가능하므로, 이러한 제약을 활용하여 차원의 저주를 탈출할 수 있다. 

## 2.6. Statistical Models, Supervised Learning and Function Approximation

model의 목표는 input과 output을 활용하여 f(x)에 더 가까운 근사를 하는 f(x) hat을 추정하는 것이다.

nearest neighbor는 조건부평균을 통해 추정하고, sqaured loss는 regression function으로 추정한다. 그러나, 추정하는데 있어서 두 가지 경우에는 문제가 발생

1. 차원이 너무 크면, 이웃간의 간격이 실제 target point와 멀어져 error를 유발
2. 특정 structure에서는 bias와 variance를 동시에 줄이는 것이 가능하다는 것

### 2.6.1. Statistical Model from the Joint Distribution Pr(X,Y)

<div>
<img src="imgs/eq_2_29.jpg">
</div>

데이터를 위와 같은 통계적 모델을 활용하여 나타내자. ![formular](https://render.githubusercontent.com/render/math?math=f(x)=E(Y|X=x)) 이며, 조건부확률은 조건부 평균 f(x)를 통해 X에 대해서만 의존적이다.

addtive model(오차를 더하는 모델)은 추정하는데 유용하다. 대부분의 모델이 (X,Y)의 pair에 대해 Y=f(x)의 관계를 가지지 않기 떄문이다. 일반적으로 Y에 기여하는 measurment error를 포함한 보이지 않은 변수들이 있다.

그리고 대부분의 ML 분류 문제는 위의 함수 양식을 따른다. 

### 2.6.2. Supervised Learning

Y=f(X)+e라는 형태를 가진 수식에서 지도학습은 (x1,y1),...,(xn,yn)의 결과값을 가지고 x값을 학습에 투입함으로써 알고리즘을 학습시킨다. 그리고 f(xi) hat을 반응으로 생성하고 실제값과의 오차를 활용하여 이를 줄여나가며 결과적으로 실제로 다른 데이터에서도 이 오차가 줄어들 수 있도록 학습한다.

### 2.6.3. Function Approximation

학습의 문제를 함수추정으로 정의하는 것은 유클리디안 공간의 위치기반의 개념과 수학적인 확률 추정으로 문제를 적용하도록 만들었다. 

<div>
<img src="imgs/eq_2_30.jpg">
<img src="imgs/eq_2_31.jpg">
<img src="imgs/eq_2_32.jpg">
</div>

추정해야하는 대상 파라미터 theta는 선형모델에서 앞서 살펴본 식(2.2)의 beta에 해당한다.

결과적으로는 linear model의 잔차 제곱의 합을 줄이는 점근과 유사하게 theta를 추정할 수 있다.

** additive error를 추가해야하는 이유?

maximum likelihood 

http://sanghyukchun.github.io/58/

## 2.7 Structured Regression Models

### 2.7.1. Difficulty of the Problem


## 2.8. Classes of Restricted Estimator

'smoothing parameter'(근접 이웃들의 수를 조절하는)

<img src="imgs/eq_2_38.jpg">

f(x)의 이중 도함수에 의헤 페널티의 강도가 결정됨. 이를 bayesian framework에 도입할 수 있으며,

J: log-prior
PRSS: log-posterior

## 2.9 Model Selection and Bias-Variance Trade off

모든 모델은 아래의 고려조건을 반영한 smoothing / complexity parameter를 가진다.

* the multiplier of the penalty term
* the width of the kernel
* the number of basis functions

lambda index가 interpolating model이 직선에 가깝도록 제약을 건다.

유사하게 local degree-m 다항식 모델의 범위를 window 사이즈가 무한대로 커지게 만들면 interpolating이 윈도우 크기를 0로 줄임으로써 fit한다.

파라미터를 결정하는데 있어서 RSS를 사용할수 없음을 말함. 0의 잔차임에도 interpolatinc fit을 하는 방안으로 선택해야함. 이런 모델은 추후의 데이터에 대해 표현을 하지 못함.

<img src="imgs/eq_2_46_47.jpg">

* sigma square: irreducible error - 새 테스트 데이터셋의 분산
* mean squard error of fk(x0) hat - bias / variance로 구분
    * variance(avg of var): k값과 avg of var은 반비례.


<img src="imgs/fig_2_11.jpg">